# NeRF介绍

## 介绍

**NeRF**（Neural Radiance Fields，神经辐射场）是一种基于神经网络的先进3D重建技术，它能够从2D图像生成高质量的3D场景。

NeRF在干一件什么事： 输入一系列的已知视角，优化NeRF来表示连续场景，最后渲染出该场景的新视角。

![1](https://github.com/user-attachments/assets/e97036ad-1098-4013-be39-025b569cd010)

用一句话说，**NeRF是一种使用神经网络来隐式表达3D场景的技术**。

## 原理

NeRF的公式表达：  $F_{\theta }:(\vec{x} ,\vec{d}) \to (\vec{c}, \sigma )$

其中 $\vec{x} = (x, y, z)$ 表示坐标， $\vec{d} = (\theta, \phi)$ 表示观测方向， $\vec{c}=(r, g, b)$ 表示预测出来的颜色值， $\sigma$ 表示体密度。

所以NeRF简单说就是利用样本数据训练好神经网络 $\theta$ ，然后就可以获得任意视角的2d视图，也就得到了完整的3d场景。 

![2](https://github.com/user-attachments/assets/52d79678-f3ba-47dc-9bdf-86561b430037)

（Rendering Loss：渲染损失）

NeRF是5D输入 $(x,y, z, \theta, \phi)$ 和 4D输出 $(r, g, b, \sigma)$ 

其中 $(\theta, \phi)$ 代表相机射线的观测方向，下图可以解释。

![3](https://github.com/user-attachments/assets/7c0c101d-fe09-4f97-98df-3ae6cf0850c5)

对于2D图像表示，我们只需要明确像素位置，即可找到对应的颜色值。

但是对于3D场景表示，我们在某个确定视点看到的2D视图就很难被单一表示出来。因为，确定视点下看到的2D图像是一组图像的**加权叠加**，而这组图像是你观测视角射线上依次采样出来的，准确来说，**2D视图上每一个像素颜色值都是3D场景上在该观测方向的射线上一组采样点的加权叠加**。

了解到这里，我们可以回头看上上张图像(a)部分，其中黑色的小圆点就是射线上的采样点，每个小圆点就能获得一组9D的训练样本  $(x,y,z,\theta,\phi,r,g,b,\sigma)$ ,可直接用来训练MLP。在推理阶段，我们也需要在观测射线进行采样。

所以，NeRF是用MLP来隐式表达一个场景，它是点对点的表示方式。我们如果想要获得一个新视角的试图，我们则需要获得这个视角下，观测射线上所有采样点的 $(x,y,z,\theta,\phi,r,g,b,\sigma)$ ，假设我们视图的分辨率是 $224\times224$ 的，每个点回引出一条射线，假设每条射线上采样 $16$ 个点，那我们 NeRF 中的 MLP 需要进行 $224\times224\times16$ 次推理，得到的结果可以用来进行体渲染。这就是NeRF的基本原理。

## 细节

### 体渲染(Volume Rendering)

在 NeRF 的训练中，NeRF 会对每条射线中的每个采样点进行预测，而我们单一新视角的 2d 视图中每一个像素点的 RGB 值需要这一条射线上所有的采样点的 $(r,g,b,\sigma)$ 值来决定。而体渲染就是做了这么一件事，它利用了光吸收的物理模型来表达。

我们对相机射线做参数表示 $r(t) = o + td$，其中 $o$ 是原点(相机光心)， $t$ 是时间。 $t_n$ 和 $t_f$ 是起始和截止时间。

 $C(r) = \int_{t_n}^{t_f}T(t)\sigma (r(t))c(r(t), d)dt, T(t) = exp(-\int_{t_n}^{t} \sigma (r(s))ds)$

上式中 $c$ 表示颜色， $\sigma$ 表示密度。

下面简单解释一下公式的含义。

这个积分宏观上满足两个条件：

1. 一个点的密度**越高**，射线通过它之后变得越弱，**密度和透光度呈反比**

2. 一个点的密度**越高**，这点在这个射线下的**颜色反应在像素上的权重越大**

$T(s)$ 的物理意义就是透明度，表示当光线到达 $s$ 处的时候，光强保留的幅度。

那么，我们继续观察 $T(s)$ 的表示，它是密度在射线上的积分后，取反后，取指数。直观上也是比较好理解的，前面经过的点密度越高，后面剩余的光越少。

而实际渲染过程中，我们进行离散化处理，把射线平均分成 $N$ 个小区间，每个区间随机采样一个点，对采样得到的点的颜色进行某种加权求和。

### 层次化体采样

原本的体渲染策略并不高效，因为均匀对待每一个采样点。但是空白区域和遮挡区域并没对渲染图像取到作用。

NeRF采用了一种层次化表示来提升渲染效率。具体做法是：**采用两个网络来表示一个场景（一个粗，一个细）**。先用普通采样来评估“粗”网络，然后用“粗”网络来制造更有信息量的采样，比如哪些采样点对体渲染更有帮助。

**粗采样**：在光线上均匀采样，根据体渲染公式获得每个采样点的权重（由体密度和位置远近共同决定）；

**细采样**：根据粗采样获得的权重，做一个光线上的归一化，将权重之和置为1，得到概率密度函数（PDF）。根据PDF来细采样，即**让更重要的线段上有更多的采样点**。  
最后，粗采样和精采样的采样点一起进入体渲染，共同作用得到像素的颜色值。

### 位置编码

位置编码是NeRF中的重要创新点之一，加入位置编码使得NeRF对于新视点重建的效果大大提升。

![4](https://github.com/user-attachments/assets/679eff3d-026d-4c7e-b172-04f82bec7f63)

具体效果我们可以看上图。其大概原理是，尽量使相邻位置的输出结果不要相似。每个位置输入$x$ ，经过位置编码以后，与相邻位置具有较大差异。
NeRF中直接采用频率变换来做位置编码，为的是**避免空间相邻采样点在MLP表示中的过平滑问题**。

公式： $\gamma (p) = (sin(2^0\pi p),cos(2^0\pi p), \cdots, sin(2^L\pi p), cos(2^L\pi p))$ 

本质上是一种广义的傅里叶变换。
